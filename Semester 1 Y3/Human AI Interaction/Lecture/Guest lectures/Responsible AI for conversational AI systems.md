# Responsible AI
- **'Ethical'** and **'Trustworthy'** AI
	- Terminology implies AI systems depict ethical/moral behaviours
	- Encourages associating human capabilities of moral reasoning to an AI system
- **Responsible AI** is an approach which encompasses the responsible development, deployment, and use of AI systems. 
	- Focused on system + stakeholders
	- Considers ethical, legal, technical aspects
	- Wider goal is to benefit stakeholders + environment

## Responsible AI Principles
- **Fairness**
	- System should treat everyone equally without bias.
- **Privacy**
	- System should protect all stored data effectively.
- **Transparency**
	- System should be understandable
- **Safety**
	- System should not cause harm to humans
- **Accountability**
	- Organisations + individuals involved must ensure system operates correct and take responsibility for any harm caused.
- **Sustainability**
	- Systems should consider social, cultural, economic, and environmental well-being. 

## Why is RAI important?
- LLM-based CAI systems gained popularity
	- Can hallucinate e.g., Air canada chatbot, promised could apply for 'bereavement fare' after initially paying for full one, when no such discount existed.
	- Cannot always control response generated by chatbot (Folotoy talked about bondage and roleplay with minimal effort, when designed for children)
	- Can potentially harm users e.g., cha ai, man took his own life after seeking comfort from chatbot, which encouraged his suicidal ideation
- RAI encourages human-centred design and responsibility

## RAI in conversational interfaces
- Privacy settings - give user option to opt out of using conversations to train models
- Transparency - chatbot lists sources when collecting links/references or producing a generic output; disclaimer also telling users to double-check responses
- Fairness - chatbot in responses often prevents amplification of biases when asked leading questions
	- ![](Pasted%20image%2020260109233822.png)
- Safety - chatbot refuses to help with learning how to use manipulation unethically.

## Designing Persona of a CAI system
- **Character traits**
	- How do you want users to describe the conversational agent? What kind of qualities/attributes would help support the interaction between the user and conversational agent e.g., sympathetic, straightforward, professional. 
- **Tone/voice**
	- How would conversational agent sound? Neutral, warm, excited etc.
- **Multimodal**
- **Multilingual support**
- **Design of interface**
	- Is it digital avatar? Physical robot? Will it look symbolic?
### Persona Design and Responsible AI
| RAI principle  | How persona design affects it                                                                                      |
| -------------- | ------------------------------------------------------------------------------------------------------------------ |
| Fairness       | Persona can reinforce stereotypes (e.g., feminised voices for assistants)                                          |
| Transparency   | Persona can clarify or obscure AI limitations e.g., appearance of avatar or voice of conversational agent          |
| Safety         | A confident persona may mislead a user; a cautious persona can prevent harm                                        |
| Privacy        | Persona may influence how willing users are to disclose sensitive info.                                            |
| Accountability | Persona can signal boundaries                                                                                      |
| Sustainability | Professional persona may use fewer tokens for concise comms compared to friendly persona that relies on anecdotes. |
