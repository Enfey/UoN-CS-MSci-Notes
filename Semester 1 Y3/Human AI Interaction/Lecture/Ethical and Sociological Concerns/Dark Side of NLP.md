Concerns how NLP technologies may negatively impact society by distorting public opinion, spreading misinformation, and creating filter bubbles.
# Bots and Fake News
- Bots can rapidly amplify false content on social media, before it goes viral.
- They post, share, reply, and mention influencers to manipulate human users.
- Bots exploit social bias - manipulating humans to resshare the fake content. 
- Study of 14 million tweets spreading 400,000 articles in 2016-2017 (Shao et al.)
	- Only 6% of accounts (bots) produced 31% of low-credibility information
	- They often act within 2-10 seconds of fake news appearing.

## Targeting Influencers
- Research by Stella, Ferrara, and De Domenico on 4M tweets during **Catalonias independence referendum**
- Bots targeted influencers who supported independence with "negative and violent content" to intensify conflict - termed **social hacking**
- Influencers often didn't realise this, and thus unspectingly amplified misinformation. 
- Regulation, laws, and incentives are needed to force social media companies to regulate their platforms. 

# Filter bubbles
- These are personalised information ecosystems shaped by:
	- Likes, views, shares
	- Friend's content
	- Browsing history, location
- They create self-reinforcing echo chambers rather than an open discourse of diverging opinions, limiting exposure to such opinions. 
- Conspiracy theories and hoaxes often spread inside filter bubbles.
- Viral spread leads to perception that "if everyone is saying it, it must be true"
## Attention Economy 
- The internet company business model is ad-revenue based - based on content "views" and "interaction" and a vast amount of other metrics.
- The currency that users pay in is "Attention" - "focused mental engagement on a particular item of information" - Davenport and Beck, "The Attention Economy"
- Recommendations are a way to lure viewers, and maximise attention gained - personalised/filtered content based on your data (history, cookies, friends, followers). Things like retweets, and likes, and for you page, and the ordering of appearance are recommendations. 
- The psychological impact of this model on the user is catastrophic - likes, shares, notifications, trigger dopamine responses and can be addictive. This is associated with rising depression and anxiety, particularly in young people where real life social groups are tight-knit and overly aware, meaning the cyber space is often a direct mirror at that time. 
	- The inquest findings of the death of Molly Russell found she took her own life while suffering from depression and had interacted with recommended harmful social media content. 
	- Could be significant case, as it hints that social media companies could be held (partially) responsible in the near future for other such incidents. 
## The problem with filter bubbles
- Algorithms may be well-intentioned (though often not), but they often instantiate alternative realities, meaning that people form disconnect with their common and immediate reality.
- In combination with the attention economy, this can lead to disconnected worldviews being formed. 
- Filter bubbles tend to amplify misinformation, spectacular, sensationalist, and emotional stories are much more likely to get shared and therefore seen, but only propagate within bubbles, leading to a sort of k-group disconnect amongst the different online subcultures. 
- Interest-based content means divergent views are filtered out of immediate view, and can promote division and hatred by not facilitating dialogue or healthy exposure to challenge. 

# Filter Bubbles: Case Studies and Research
## Cambridge Analytica
- Harvested data from 50M facebook users under false pretenses ("personality quiz")
- Users targeted political ads on the basis of these quizzes during the 2016 US election and Brexit referendum. 
- Whistleblowers revealed the large-scale manipulation of voter behaviour, manipulating political outcomes via the distorted filter bubbles invoked as a result of political advertisements. 
- Research linked Filter bubbles with this political outcome:
	- Active social media use for politics was related to less support for republican populists such as Trump
	- Passive or uncivil social media use were linked to an increase in likelihood to support Republican populism in general, and Trump in particular.

## Are we all stuck in bubbles?
- Benchmann & Nielbo (2018):
	- Analysed 1000 Facebook news feeds from 1000 Danish users
	- Only 10-28% of Danish Facebook users were in distinct filter bubbles
	- Users' own behaviour is a major predictor - page likes, group memberships, and friends, thus **self-selection** - users themselves actively enhance the likelihood of being in a bubble.
- Flaxman et al(2016)
	- Studied web browsing history of 50,000 people in USA
	- Social networks and search engines are associated with an increase in the mean **ideological distance** between individuals
	- Counterintuitively, these same channels also are associated with an increase in an individual's exposure to cross-ideological content, but the effects are modest, and the underlying inclination is often reinforced by recommended content. 

## Covid "Infodemic"
- Misinformation had 500bn views in April 2020 alone on Facebook
- Fake stories included that the virus was a hoax, or drinking concentrated alcohol or other chemicals would make individuals immune/heal them etc
- Research suggests a single piece of misinformation caused **800 deaths**

## Solutions
1. Fact-Checking
	- Orgnaisations such as politifact and snopes verify the accuracy of outlandish or political claims
	- Political debates are often "fact-checked" live by journalists.
2. Education
	- Propagation of mental tooling to combat fake news and steer toward reputable, non-biased sources of news and avoiding being a driver of misinformation is of paramount importance in stopping the war of misinformation.
3. Tools and technological improvements
	- Better content moderation and flagging systems, and algorithmic transparency help remove biased content, remove bot accounts that propagate harmful content, and promote trust in social media to provide relevant and unbiased information to its users.
4. Regulation
	- Regulation compels corporations to do the right thing, and there is often attached incentives included with this. E.g., data protection, Online Safety Act "companies must take preventative measures including design measures, to mitigate a broad spectrum of factors that enable illegal activity, both on and offline". 