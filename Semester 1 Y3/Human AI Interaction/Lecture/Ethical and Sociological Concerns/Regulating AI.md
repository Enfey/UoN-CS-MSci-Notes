## Why Regulate Technology at All?
### Technology's Impact on the Society, Behaviors and Social Outcomes
- AI profoundly influences human behaviour, determining how individuals interact with each other and access essential services. 
- Integration of technology, reshaped social interactions, educational opportunities, economic engagements
- Necessitates regulatory oversight to ensure equitable access and ethical usage.
### AI Magnifies Societal Risks
- Amplifies existing risks within societal frameworks and hierarchies. These include:
	- Algorithmic bias that can lead to discriminatory outcomes
	- Misinformation disrupting social trust
	- Safety failures that endanger public health
	- Privacy breaches that threaten individual rights
- If left unregulated, AI will inevitably cause significant and potentially irreversible societal harms. 

## Classic Dilemma of Regulation
- **Regulate Too Early: Innovation vs Stagnation**
	- When regulation is premature, can stifle innovation, commonly referred to as 'regulation chill'. This stifling effect may hinder development of new technologies, and limit the scope of their benefit. 
	- As technology evolves at a rapid pace, the legal frameworks in place often become obsolete, failing to address nuances of emergent technologies
- **Regulate Too Late: Risks & Consequences**
	- Conversely, delaying regulation allows harmful practices to become entrenched, making remediation more challenging
	- When regulation is reactive rather than proactive, societal issues can solidify, leading to entrenched power dynamics that may disadvantage certain groups. 
	- Delays exacerbate risks such as privacy violations, and are difficult to rectify once established. 

### Precautionary Principle vs Innovation Principle
- **Precautionary Principle**
	Advocates for proactive regulation to prevent potential harm, emphasising caution, especially in the face of scientifiec uncertainty, and seeks to safeguard public welfare by acting pre-emptively.
- **Innovation Principle**
	Prioritises technologic advancement and economic growrth over immediate regulatory interventions. Suggests regulations should only be enacted after harms have occurred; fosters environment conducive to rapid experimentation and development. 

## UK approach to Regulating AI
- UK adopts sector-specific strategy that avoids a singular, overarching AI law. Regulations are tailored to individual sectors and industries in the UK. 
- Chooses to emphasise empowerment of existing regulatory bodies to oversee AI technologies, fostering a pro-innovation environment while safeguarding public interests. 
	- Several existing regulatory bodies are tasked with overseeing AI applications in their respective domains. These include the:
		- **Information Commissioners Office (ICO)** - data protection
		- **Competition and Markets Authority (CMA)** - addresses fair market and monopoly issues
		- **Ofcom**
		- **Financial conduct Authority (FCA)** - oversees general financial services and conduct.
		- **The Medicines and Healthcare products Regulatory Agency (MRHA)** - ensures safety in healthcare products and services.

### Online Safety Act (OSA, 2023)
- Introduces comprehensive measures aimed at safeguarding users in the digital landscape, particularly addressing the unique challenges posed by AI-driven algorithmic systems
- Mandates platforms to implement **safeguards**, **risk assessments**, to mitigate harms associated with automated content moderation and recommendation algorithms.
- Regulates algorithmic amplification, covers user-generated content. 

### Data Protection Act 2018 & UK GDPR
- The DPA serves as a cornerstone for regulating data processing, establishing a safeguarding framework centered on individual privacy rights. 
- Incorporates components from GDPR.
- **Transparency in Data Processing**
- **Fairness (in AI systems)**
	- Individuals should not be subjected to unjust treatment based on automated decision-making processes. 
	- Must mitigate bias from the outset, navigate anti-discrimination laws, and ensure equitable outcomes for all.
- **Accountability for Data Practices**
	- Requires implementation of measures that ensure compliance with DP regulations. 
- **Data Minimisation Principle**
	- Collect minimum data possible for specific purpose of processing, ensures large datasets do not infringe on individual privacy rights.
- **Rights of Data Subjects**
	- Autonomy reinforced; users can control their information, submit deletion requests etc.

### Equality Act 2010 and Algorithmic Bias
- AI systems deployed in sensitive areas e.g., employment, housing, credit, policing, must adhere to principles of non-discrimination
- Algorithmic bias, can arise from flawed training data or biased algorithms, risk perpetuating existing inequalities, must mitigate to comply. 

### UK AI Regulation (2023 White Paper)
#### No New AI Regulator
- UK gov elected to empower and expand the roles of existing regulatory bodies rather than establish dedicated AI regulatory body
- Leverages expertise and operational experience of established organisations to effectively oversee AI technologies. 

#### Five Cross-Sector Principles
- The UK AI regulation framework is grounded in **five** foundational principles that guide all sectors in the regulation of AI
	1. **Safety**
	2. **Transparency and explainability**
	3. **Fairness** - comply with existing laws, avoid discrimination
	4. **Accountability and governance**
	5. **Provide mechanisms for contestability and redress** - need clear ways to dispute harmful AI outcomes. #


## EU AI Act
- Introduces a structured regulatory framework categorising AI systems based on their risk levels, from unacceptable to minimal risk. 
### Why the EU Regulated Early
- **Desire for Global Leadership**
	- Ambition to position itself as global leader in AI governance, reflects the 'Brussels effect' - ability of EU regulations to influence global standards
	- By regulating early, sets a precedence for ethical AI deployment, and fosters international co-operation.
- **Public pressure over AI Harms**
	- Public concern regarding harm of AI technologies has driven policymakers to act swiftly; incidents of algorithmic bias, privacy infringements, misinformation campaigns etc.
	- Demand therefore heightened for prescription of regulatory frameworks to protect citizens.
- **Fear of unregulated AI in safety-critical sectors**
	- EU expressed concerns about proliferation of unregulated AI technologies.
	- Without timely intervention, feared that harmful practices could become entrenched, resulting in adverse societal effects. 
### Structure of the EU AI Act
- EU AI act categories systems into **four** distinct tiers based on risk-level, enabling targeted regulation and remediation for deployers. 
- **Unacceptable risk - banned** - Examples of AI systems that pose inacceptable risks include social scoring by governments, real-time biometric identification in public spaces, and manipulative AI.
- **High risk - heavily regulated** - Medical diagnostic tools, recruitment algorithms, essential public services, subject to strict compliance and oversight.
- **Limited risk - transparency obligations** - AI applications classified as limited risk must adhere to transparency rules such as chatbots disclosing their AI nature and emotion recongiti
- **Minimal risk - largely unregulated**
